# ‚öñÔ∏è AI Legal & Government Awareness Assistant (GenAI + RAG)

A **topic-aware GenAI system** that provides **accurate, hallucination-free legal and government information** using **Retrieval-Augmented Generation (RAG)** and a **local Large Language Model (LLM)**.

The system is designed with **strict topic isolation**, **safety constraints**, and **production-style architecture** to ensure reliable public awareness responses.

> ‚ö†Ô∏è This project is for **public information only**. It does **not provide legal advice**.

---

## üéØ Key Capabilities

- Topic-aware **RAG pipeline** (prevents cross-topic hallucination)
- Metadata-filtered **FAISS vector search**
- **Local LLM (Ollama ‚Äì Llama3)** ‚Üí no paid APIs
- Strict **safety & disclaimer enforcement**
- Modern, animated **Streamlit UI**
- Dark / Light mode with chat history
- Clean separation of **UI and AI logic**

---

## üèõ Supported Domains

### Government
- Aadhaar
- PAN Card
- Voter ID

### Legal
- FIR / Police Procedure
- Consumer Rights
- Tenant Rights

Out-of-scope queries are **safely declined**.

---

## üèó System Architecture

Streamlit UI
‚îÇ
‚ñº
FastAPI Backend (/ask)
‚îÇ
‚ñº
Topic Detection
‚îÇ
‚ñº
FAISS Vector Search (metadata-filtered, k=1)
‚îÇ
‚ñº
Context Injection
‚îÇ
‚ñº
Local LLM (Ollama ‚Äì Llama3)


---

## üõ† Technology Stack

| Layer | Tools |
|-----|------|
| Frontend | Streamlit |
| Backend | FastAPI |
| LLM | Ollama (Llama3) |
| RAG | LangChain |
| Vector Store | FAISS |
| Embeddings | Sentence Transformers |
| Language | Python |

---

## üß† Engineering Highlights

- Enforced **single-topic retrieval (k=1)** to eliminate answer mixing
- Applied **metadata-based filtering** for document isolation
- Added **prompt-level constraints** to prevent unsafe responses
- Fully decoupled UI from backend to avoid regression during UI changes
- Designed for **local execution** without dependency on paid APIs

---

## ‚ñ∂Ô∏è Local Setup

### Install Dependencies
```bash
pip install -r requirements.txt

Start LLM
ollama pull llama3

Run Backend
uvicorn app.main:app --reload

Run Frontend
streamlit run frontend/streamlit_app.py

üß™ Example Queries

How to apply for Aadhaar?

What is the FIR filing procedure?

What are tenant rights?

What are consumer rights?

üîê Safety Considerations

No legal advice or case predictions

No personal data handling

Explicit disclaimers on every response

Designed strictly for public awareness

üöÄ Deployment Notes

Optimized for local deployment (interviews, demos)

Backend: FastAPI + Uvicorn

Frontend: Streamlit

Ollama is intended for local execution.
Cloud deployment requires a hosted LLM replacement.

üë§ Author

Muhammed Ansil
B.Tech ‚Äì Artificial Intelligence & Data Science
Interests: GenAI, RAG Systems, AI Engineering

‚≠ê Acknowledgement

If this project is useful, feel free to ‚≠ê the repository.

**STOP COPYING HERE ‚¨ÜÔ∏è**

---

## üß† SIMPLE RULE (REMEMBER THIS)

> **README = final product description**  
> **Chat = learning & guidance**

Only the **clean markdown content** belongs in the repo.

---

## ‚úÖ WHAT TO DO NOW (SAFE STEPS)

1Ô∏è‚É£ Open `README.md`  
2Ô∏è‚É£ **Delete everything inside**  
3Ô∏è‚É£ Paste **only the markdown section above**  
4Ô∏è‚É£ Save  
5Ô∏è‚É£ `git add README.md`  
6Ô∏è‚É£ `git commit -m "Add concise senior-level README"`  
7Ô∏è‚É£ `git push`

---

## üöÄ NEXT (YOUR CHOICE)

Reply with one:

- **`RESUME POINTS`** ‚Üí Convert this project into strong CV bullets  
- **`LINKEDIN POST`** ‚Üí Professional post for recruiters  
- **`INTERVIEW EXPLANATION`** ‚Üí How to explain this project clearly  

You‚Äôre doing this **the right way** ‚Äî this level of care is exactly what stands out üëå